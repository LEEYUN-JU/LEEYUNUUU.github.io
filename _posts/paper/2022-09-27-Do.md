---
layout: post
title: Do Adversarially Robust ImageNet Models Transfer Better?
comments: true
categories : [paper]
published: true

---

### Introduction
Transfer learning이란? 
-> A데이터 셋으로 학습 시키고 B데이터 셋을 가지고 테스트 하거나 적용하는것.
학습을 시키고 그것을 토대로 테스트를 진행하지만, 실제 생활에서 사용하는 경우, 모델이 접하게 되는 정보는 학습한 데이터 셋에 포함되어 있지 않기 때문에 혼란을 초래하거나, 정확도가 떨어진다.

이에, 학습한 데이터 셋 말고 다른 데이터 셋에서도 모델이 잘 구분할 수 있게 하는 연구가 바로 transfer learning 이다. 

본 논문에서는 Adversarial robustness 를 활용하여 실험을 진행하고자 한다.

> 1. fixed-feature : 전체적인 학습 과정에서 classification 부분만 custom하는 것
> 2. full-network : initial weight만 사용하고, 나머지 부분은 다 fine-tuning 하는 것

 ### Motivation
 과연 Pre-trained 된 모델의 정확도가 높으면, 그 모델은 transfer learning performance 에서도 좋은 성능을 보여주는 가? 에 대한 의문에서 시작하게 된다.

높은 정확도가 반드시 transfer learning 에 영향을 미치는 것도 아니다.

실험을 설명하기 전에 알아 두어야 할 것 두 가지가 있다.
> Adversarial attack : 사람의 눈으로 인지하기 힘든 수준의 노이즈를 원본 이미지에 발생시켜 모델에게 학습시키게 되면, 모델은 이를 받아들여서 엉뚱한 정답을 내민다. 이것을 바로 Adversarial attack 이라고 한다.
> Adversarial robustness : 똑같은 과정을 진행하고, 노이즈에도 불구하고 모델이 정답을 유추해낼 수 있도록 하는 기법을 Adversarial robustness 라고 한다.

이에 사용되는 loss 식은 다음과 같다.
![enter image description here](https://ifh.cc/g/QRZA3G.png)

Loss 식의 변화보다는 epslion을 활용하여 이미지를 변화시키고 이를 training 시켰다는 사실이 더 중요하다.
